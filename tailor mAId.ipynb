{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xofmSYlAkjsE"
      },
      "outputs": [],
      "source": [
        "# importing requests and json\n",
        "import torch\n",
        "import torchvision\n",
        "import requests, json\n",
        "from enum import Enum\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "!pip install anvil-uplink\n",
        "!pip install git+https://github.com/ricardodeazambuja/colab_utils.git\n",
        "!pip install google-cloud-speech\n",
        "!pip install pydub\n",
        "from google.cloud import speech\n",
        "import anvil.server\n",
        "import numpy as np\n",
        "!pip install psycopg2\n",
        "import psycopg2\n",
        "!pip install timm\n",
        "import timm\n",
        "from PIL import Image\n",
        "!pip install -U keras-efficientnet-v2\n",
        "!pip install -U keras_cv_attention_models \n",
        "from colab_utils import getAudio\n",
        "from scipy.io.wavfile import write\n",
        "import io\n",
        "from io import BytesIO\n",
        "!pip install colorthief\n",
        "from colorthief import ColorThief\n",
        "from google.colab import files\n",
        "import os\n",
        "!pip install webcolors\n",
        "from scipy.spatial import KDTree\n",
        "from webcolors import CSS3_HEX_TO_NAMES, hex_to_rgb\n",
        "!pip install openai\n",
        "import openai\n",
        "import random\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaDjyCdIPrWb"
      },
      "outputs": [],
      "source": [
        "# some initial setup\n",
        "\n",
        "is_woman = True # changed in code depending on who is the user\n",
        "preferred_skin_tone = \"asian\"\n",
        "\n",
        "anvil.server.connect(\"anvil server key\")\n",
        "\n",
        "openai.api_key = \"\" #api key ere\n",
        "\n",
        "class Temperature(Enum):\n",
        "    FREEZING = 1\n",
        "    MODERATE = 2\n",
        "    HOT = 3\n",
        "    \n",
        "temperature_mapping = {\n",
        "  \"sandal\" : 3,           # probs not gonna use\n",
        "  \"runningshoe\" : 2,           # probs not gonna use\n",
        "  \"kimono\" : 3 ,\n",
        "  \"overskirt\" : 3,\n",
        "  \"labcoat\" : 2,\n",
        "  \"militaryuniform\" : 2,\n",
        "  \"brassiere\" : 3,           # probs not gonna use\n",
        "  \"poncho\" : 2,\n",
        "  \"apron\":3,\n",
        "  \"miniskirt\":3,\n",
        "  \"jersey\" : 3,\n",
        "  \"cardigan\" : 3,\n",
        "  \"sweatshirt\" : 2,\n",
        "  \"furcoat\" :1,\n",
        "  \"cloak\" : 2,\n",
        "  \"suit\" : 2,\n",
        "  \"jean\":3,\n",
        "  \"bowtie\" : 3,           # probs not gonna use\n",
        "  \"trenchcoat\" : 2,\n",
        "  \"necklace\" : 3,           # probs not gonna use\n",
        "  \"purse\" : 3,           # probs not gonna use\n",
        "  \"sock\" : 2,           # probs not gonna use\n",
        "  \"bikini\" : 3,           # probs not gonna use\n",
        "  \"backpack\" : 2,           # probs not gonna use\n",
        "  \"mask\" : 1,           # probs not gonna use\n",
        "}\n",
        "\n",
        "# tops_list = [\"kimono\", \"labcoat\", \"militaryuniform\", \"poncho\", \"apron\", \"jersey\", \"cardigan\", \"sweatshirt\", \"furcoat\", \"cloak\", \"suit\", \"trenchcoat\"]\n",
        "# bottoms_list = [\"overskirt\", \"miniskirt\", \"jean\"]\n",
        "tops_list = [\"kimono\", \"labcoat\", \"militaryuniform\", \"poncho\", \"apron\", \"jersey\", \"cardigan\", \"sweatshirt\", \"furcoat\", \"cloak\", \"suit\", \"trenchcoat\", \"shirt\", \"sweater\", 'jacket', 'tshirt', 'tanktop']\n",
        "bottoms_list = [\"overskirt\", \"miniskirt\", \"jean\", \"sweatpants\", \"shorts\", 'jeans']\n",
        "\n",
        "'''GETTING THE WEATHER'''\n",
        "# base URL\n",
        "BASE_URL = \"https://api.openweathermap.org/data/2.5/weather?\"\n",
        "# City Name \n",
        "CITY = \"Montreal\"\n",
        "# API key \n",
        "API_KEY = \"69f2add663081b7872b6c7fbb3a22d3e\"\n",
        "#https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={API key}\n",
        "# upadting the URL\n",
        "URL = BASE_URL + \"q=\" + CITY + \"&appid=\" + API_KEY\n",
        "# HTTP request\n",
        "response = requests.get(URL)\n",
        "# checking the status code of the request\n",
        "if response.status_code == 200:\n",
        "   # getting data in the json format\n",
        "   data = response.json()\n",
        "   # getting the main dict block\n",
        "   main = data['main']\n",
        "   # getting temperature\n",
        "   temperature = round(main['temp'] - 273, 2)\n",
        "   # getting the humidity\n",
        "   humidity = main['humidity']\n",
        "   # getting the pressure\n",
        "   pressure = main['pressure']\n",
        "   # weather report\n",
        "   report = data['weather']\n",
        "   print(f\"{CITY:-^30}\")\n",
        "   print(f\"Temperature: {temperature}\")\n",
        "   print(f\"Humidity: {humidity}\")\n",
        "   print(f\"Pressure: {pressure}\")\n",
        "   print(f\"Weather Report: {report[0]['description']}\")\n",
        "\n",
        "# sorting based on temperature \n",
        "\n",
        "if -50 <= temperature < 5:\n",
        "  current_temp = Temperature.FREEZING\n",
        "elif 5 <= temperature <= 20:\n",
        "  current_temp = Temperature.MODERATE\n",
        "else: # temps > 20\n",
        "  current_temp = Temperature.HOT\n",
        "print(current_temp)\n",
        "\n",
        "freezing_storage = {}\n",
        "moderate_storage = {}\n",
        "hot_storage = {}\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/speech-to-text-key.json'\n",
        "os.environ['PROJECT_ID'] = 'codejam-12'\n",
        "!ls -l $GOOGLE_APPLICATION_CREDENTIALS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHPX3yD6Orpc"
      },
      "source": [
        "-50 to 5: freezing : coats, fur coats, boots\n",
        "\n",
        "5 to 20: moderate : jackets, cardigans, sweatshirts, shoes\n",
        "\n",
        "20+ hot : tshirts, swimsuits, sandals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6A1-VqNdTXj"
      },
      "source": [
        "use 1k for clothing thickness, 21k is too precise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kir7OJUbpn1H"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWNYfdt-ZIuI"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def change_skintone(tone):\n",
        "  preferred_skin_tone = tone\n",
        "\n",
        "@anvil.server.callable\n",
        "def change_style(style):\n",
        "  is_woman = style\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WjKgxVDpLuY"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "# setup audio recon\n",
        "\n",
        "triggers = {\"tailor\", \"taylor\", \"tayler\", \"tailer\", \"taler\", \"teller\", \"tyler\", \"toiler\", \"cater\", \"peter\", \"meter\", \"beater\", \"Baylor\", \"Paylor\", \"Taylor's\", \"Tailor's\", \"sailor\", \"hayler\", \"hailer\", \"trainer\"}\n",
        "command_bank = {\"drip\", \"trip\", \"grip\", \"outfit\", \"outfits\", \"suggest\", \"wear\", \"weather\", \"clothes\", \"fits\", \"fit\", \"dress\", \"gym\", \"frigid\", \"icy\", \"cool\"}\n",
        "cold_terms = {\"cold\", \"snow\", \"frosty\", \"freeze\", \"winter\", \"freezing\", \"chilly\", \"icy\"}\n",
        "moderate_terms = {\"spring\", \"fall\", \"autumn\", \"moderate\", \"temperate\", \"soft\", }\n",
        "hot_terms = {\"inside\", \"hot\", \"sunny\", \"summer\", \"sweating\", \"home\", \"canicule\", \"heatwave\", \"heat\", \"overheating\", \"tropical\", \"warm\", \"muggy\", \"boiling\", \"scorching\", \"sweltering\", \"searing\", \"blistering\"}\n",
        "\n",
        "# returns a url to the image of the person wearing clothes\n",
        "@anvil.server.callable\n",
        "def get_command(wav_bytes):\n",
        "  # audio, sr = getAudio() #html button to record audio\n",
        "  # print(len(audio))\n",
        "\n",
        "  # wav_bytes = io.BytesIO()\n",
        "  # write(wav_bytes, 44100, audio)\n",
        "\n",
        "  # \n",
        "  audio_b = wav_bytes.get_bytes()\n",
        "  audio_ogg = io.BytesIO(audio_b)\n",
        "  audio_wav = io.BytesIO()\n",
        "\n",
        "  file = AudioSegment.from_file(audio_ogg)\n",
        "  file.export(audio_wav, format='wav', parameters=[\"-ac\", \"1\"], bitrate=\"192k\")\n",
        "  audio_wav.seek(0)\n",
        "  audio = speech.RecognitionAudio(content=audio_wav.read())\n",
        "  config = speech.RecognitionConfig(\n",
        "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "        sample_rate_hertz= file.frame_rate, # Value of the sample rate of the dell mics, TODO: Parse wav for proper rate\n",
        "        language_code=\"en-US\",\n",
        "    )\n",
        "  \n",
        "  speech_client = speech.SpeechClient()\n",
        "  response = speech_client.recognize(config=config, audio=audio)\n",
        "\n",
        "  words = \"\"\n",
        "\n",
        "  for result in response.results:\n",
        "    #print(\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
        "    words += result.alternatives[0].transcript\n",
        "    print(\"words: \", words)\n",
        "  output_words = words\n",
        "  tailor_detected = False\n",
        "  command_detected = False\n",
        "  weather = current_temp\n",
        "  return_string = \"\" \n",
        "  for word in words.split():\n",
        "    print(\"checking for 'tailor':\", word)\n",
        "    if word.lower() in triggers:\n",
        "      tailor_detected = True\n",
        "      return_string += \"trigger detected: \"\n",
        "      break\n",
        "\n",
        "  if tailor_detected:\n",
        "    for word in words.split():\n",
        "      print(\"checking word: \", word)\n",
        "      if word.lower() in command_bank:\n",
        "        return_string += \"command detected\"\n",
        "        command_detected = True\n",
        "      elif word.lower() in cold_terms:\n",
        "        return_string += \"cold weather term: \" + word + \" :\"\n",
        "        weather = Temperature.FREEZING\n",
        "        command_detected = True\n",
        "      elif word.lower() in moderate_terms:\n",
        "        return_string += \"moderate weather term: \" + word + \" :\"\n",
        "        weather = Temperature.MODERATE\n",
        "        command_detected = True\n",
        "      elif word.lower() in hot_terms:\n",
        "        return_string += \"hot weather term: \" + word + \" :\"\n",
        "        weather = Temperature.HOT\n",
        "        command_detected = True\n",
        "\n",
        "  else:\n",
        "    return_string += \"trigger word not detected in \" + output_words + \" (\" + str(len(audio_b)) + \") at \" + str(file.frame_rate) +\", try again\"\n",
        "\n",
        "  if command_detected:\n",
        "    if is_woman:\n",
        "      gender = \"woman\"\n",
        "    else:\n",
        "      gender = \"man\"\n",
        "    print(\"Generating...\")\n",
        "    url = generate_image(gender, preferred_skin_tone, weather)\n",
        "  else: \n",
        "    return return_string, None # No commands, dont bother\n",
        "    # sends the url as string to the client\n",
        "    # anvil.server.call(\"set_image\", url)\n",
        "\n",
        "    #do smth with the url\n",
        "  return_string += output_words + \" (\" + str(len(audio_b)) + \") at \" + str(file.frame_rate)\n",
        "  return return_string, url\n",
        "\n",
        "  # should return success, weather (0 = weather api, 1 = cold, 2 = moderate, 3 = hot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM3eOPp3qZM8"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "\n",
        "def generate_image(gender, skintone, weather = current_temp):\n",
        "  prompt = \"modern photo of {} {} wearing a {} {} and {} {}, white background\"\n",
        "  #prompt = \"realistic photo of {} {} wearing a {} {} and {} {}\"\n",
        "\n",
        "  if weather == Temperature.FREEZING:\n",
        "    clothing_top, color_top, clothing_bottom, color_bottom = select_clothes(freezing_storage, moderate_storage)\n",
        "  \n",
        "  elif weather == Temperature.MODERATE:\n",
        "    if random.randint(0,1) == 0:\n",
        "      clothing_dict = freezing_storage\n",
        "    else:\n",
        "      clothing_dict = hot_storage\n",
        "    clothing_top, color_top, clothing_bottom, color_bottom = select_clothes(moderate_storage, clothing_dict)\n",
        "\n",
        "  elif weather == Temperature.HOT:\n",
        "    clothing_top, color_top, clothing_bottom, color_bottom = select_clothes(moderate_storage, hot_storage)\n",
        "\n",
        "  final_prompt = prompt.format(skintone, gender, color_top, clothing_top, color_bottom, clothing_bottom)\n",
        "  print(final_prompt)\n",
        "\n",
        "  response = openai.Image.create(\n",
        "  prompt=final_prompt,\n",
        "  n=1,\n",
        "  size=\"512x512\"\n",
        "  )\n",
        "  image_url = response['data'][0]['url']\n",
        "\n",
        "  print(clothing_top, color_top, clothing_bottom, color_bottom)\n",
        "  print(image_url)\n",
        "\n",
        "  return image_url\n",
        "\n",
        "#test function\n",
        "#generate_image(\"man\", \"asian\", Temperature.MODERATE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_image(\"man\", \"caucasian\", Temperature.FREEZING)"
      ],
      "metadata": {
        "id": "47M3rslur2Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDerX7RaiXHB"
      },
      "outputs": [],
      "source": [
        "def select_clothes(dict1, dict2):\n",
        "  if random.randint(0,1) == 0:\n",
        "    clothing_dict = dict1\n",
        "  else:\n",
        "    clothing_dict = dict2\n",
        "  \n",
        "  #pick top\n",
        "  # while True:\n",
        "  #   clothing_top, color_list_top = random.choice(list(clothing_dict.items()))\n",
        "  #   if clothing_top in tops_list:\n",
        "  #     break;\n",
        "  clothing_top = random.choice(list(set(clothing_dict) & set(tops_list)))\n",
        "  color_top = random.choice(clothing_dict[clothing_top])\n",
        "\n",
        "  #pick bottom\n",
        "  # while True:\n",
        "  #   clothing_bottom, color_list_bottom = random.choice(list(clothing_dict.items()))\n",
        "  #   if clothing_bottom in bottoms_list:\n",
        "  #     break;\n",
        "  clothing_bottom = random.choice(list(set(clothing_dict) & set(bottoms_list)))\n",
        "  color_bottom = random.choice(clothing_dict[clothing_bottom])\n",
        "\n",
        "  return clothing_top, color_top, clothing_bottom, color_bottom\n",
        "\n",
        "# clothing_top, color_top, clothing_bottom, color_bottom = select_clothes(freezing_storage, moderate_storage)\n",
        "# print(clothing_top, color_top, clothing_bottom, color_bottom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jux3eU3PpUPM"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def get_weather():\n",
        "  #print(f\"{CITY:-^30}\\n Temperature: {temperature}\\n Weather Report: {report[0]['description']}\")\n",
        "  return f\"{CITY:-^30}\\n Temperature: {temperature}Â°C\\n Humidity: {humidity}%\\n Weather: {report[0]['description']}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdljLhGoz062"
      },
      "outputs": [],
      "source": [
        "get_weather()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZb5vQCwz04j"
      },
      "outputs": [],
      "source": [
        "# color converter\n",
        "\n",
        "def convert_rgb_to_names(rgb_tuple):\n",
        "    # a dictionary of all the hex and their respective names in css3\n",
        "    css3_db = CSS3_HEX_TO_NAMES\n",
        "    names = []\n",
        "    rgb_values = []\n",
        "    for color_hex, color_name in css3_db.items():\n",
        "        names.append(color_name)\n",
        "        rgb_values.append(hex_to_rgb(color_hex))\n",
        "    \n",
        "    kdt_db = KDTree(rgb_values)\n",
        "    distance, index = kdt_db.query(rgb_tuple)\n",
        "    return names[index]\n",
        "\n",
        "def get_color(image):\n",
        "\n",
        "  width,height = image.size\n",
        "  new_width = width*2//5\n",
        "  new_height = height*2//5\n",
        "  left = (width - new_width)/2\n",
        "  right = (width + new_width)/2\n",
        "  top = (height - new_height)/2\n",
        "  bottom = (height + new_height)/2\n",
        "\n",
        "  # Crop the center of the image\n",
        "  im = image.crop((left, top, right, bottom))\n",
        "  im.save(\"image_cropped.png\")\n",
        "\n",
        "  color_thief = ColorThief('image_cropped.png')\n",
        "  dominant_color = color_thief.get_color(quality=1)\n",
        "  !rm image_cropped.png\n",
        "  from webcolors import rgb_to_name\n",
        "  named_color = convert_rgb_to_names(dominant_color)\n",
        "  return(named_color)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image5 = Image.open('KDF-codejam12/Untitled.png')\n",
        "get_color(image5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AwyssbBikr91",
        "outputId": "400135de-5e8c-418d-d672-3bd67d77a38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'firebrick'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnhC7eDVAqwp",
        "outputId": "fe195adc-d395-47d3-f7bb-977704615720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KDF-codejam12'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 81 (delta 32), reused 40 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/iveykun/KDF-codejam12.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding clothing by default\n",
        "whitecolor = 'cyan'\n",
        "blackcolor = 'black'\n",
        "freezing_storage['furcoat'] = [blackcolor, \"grey\"]\n",
        "freezing_storage['jeans'] = [blackcolor, \"blue\", \"grey\"]\n",
        "freezing_storage['jacket'] = [blackcolor, \"blue\", \"grey\", \"green\"]\n",
        "\n",
        "moderate_storage['cardigan'] = [whitecolor, blackcolor, \"blue\", \"green\", \"grey\"]\n",
        "moderate_storage['shorts'] = [whitecolor, blackcolor, \"blue\", \"grey\"]\n",
        "moderate_storage['shirt'] = [whitecolor, blackcolor, \"blue\", \"green\", \"grey\"]\n",
        "moderate_storage['sweatpants'] = [whitecolor, blackcolor, \"grey\"]\n",
        "moderate_storage['sweater'] = [whitecolor, blackcolor, \"blue\", \"green\", \"grey\"]\n",
        "moderate_storage['jeans'] = [blackcolor, \"blue\", \"grey\"]\n",
        "\n",
        "hot_storage['jersey'] = [whitecolor, blackcolor, \"blue\", \"green\", \"grey\"]\n",
        "hot_storage['shorts'] = [whitecolor, blackcolor, \"blue\", \"grey\",]\n",
        "hot_storage['miniskirt'] = [whitecolor, blackcolor, \"blue\", \"green\", \"grey\"]\n",
        "hot_storage['tshirt'] = [whitecolor, blackcolor, \"blue\", \"green\", \"grey\"]\n",
        "hot_storage['sweatpants'] = [whitecolor, blackcolor, \"blue\", \"green\", \"grey\"]\n",
        "hot_storage['tanktop'] = [whitecolor, blackcolor, \"blue\", \"green\", \"grey\"]\n"
      ],
      "metadata": {
        "id": "othgsA6zqIy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqm5hLkpLscU"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def imagenet1kmedia(mediaobject):\n",
        "  #response = requests.get(str(link))\n",
        "  obj = mediaobject.get_bytes()\n",
        "  img = Image.open(BytesIO(obj))\n",
        "  #model = timm.create_model('mobilenetv3_large_100_miil_in21k', pretrained=True)\n",
        "  model = torchvision.models.resnet101(pretrained=True)\n",
        "\n",
        "  #img_1 = Image.open(\"drive/My Drive/codejam/test1.png\").convert('RGB')\n",
        "  #img_1 = Image.open(image).convert('RGB')\n",
        "\n",
        "  preprocess = torchvision.transforms.Compose([\n",
        "          torchvision.transforms.Resize(256),\n",
        "          torchvision.transforms.CenterCrop(224),\n",
        "          torchvision.transforms.ToTensor(),\n",
        "          torchvision.transforms.Normalize(\n",
        "          mean=[0.485, 0.456, 0.406],\n",
        "          std=[0.229, 0.224, 0.225]\n",
        "      )])\n",
        "  # CHANGE THIS FOR DIFFERENT IMAGES \n",
        "  img_preprocessed = preprocess(img)\n",
        "  # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  batch_img_cat_tensor = torch.unsqueeze(img_preprocessed, 0)\n",
        "  model.eval()\n",
        "  # source: https://vitalflux.com/pytorch-load-predict-pretrained-resnet-model/\n",
        "  out = model(batch_img_cat_tensor)\n",
        "  \n",
        "  with open('KDF-codejam12/imagenet_classes.txt') as f:\n",
        "      labels = [line.strip() for line in f.readlines()]\n",
        "  _, index = torch.max(out, 1)\n",
        "  percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "  print(labels[index[0]], percentage[index[0]].item())\n",
        "  _, indices = torch.sort(out, descending=True)\n",
        "  [(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]\n",
        "  tag = labels[index[0]].split(\",\")[0].replace(\" \", \"\")\n",
        "  # so add imagebytes, temp, tag\n",
        "  newcolor = get_color(img)\n",
        "  #print(newcolor)\n",
        "  temp = temperature_mapping[tag]\n",
        "\n",
        "  if temp == 1:\n",
        "    if tag not in freezing_storage:\n",
        "      freezing_storage[tag] = [newcolor]\n",
        "      moderate_storage[tag] = [newcolor]\n",
        "    else:\n",
        "      freezing_storage[tag].append(newcolor)\n",
        "      moderate_storage[tag].append(newcolor)\n",
        "  elif temp == 2:\n",
        "    if tag not in moderate_storage:\n",
        "      freezing_storage[tag] = [newcolor]\n",
        "      moderate_storage[tag] = [newcolor]\n",
        "      hot_storage[tag] = [newcolor]\n",
        "    else:\n",
        "      freezing_storage[tag].append(newcolor)\n",
        "      moderate_storage[tag].append(newcolor)\n",
        "      hot_storage[tag].append(newcolor)\n",
        "  else: # must be 3\n",
        "    if tag not in hot_storage:\n",
        "      moderate_storage[tag] = [newcolor]\n",
        "      hot_storage[tag] = [newcolor]\n",
        "    else:\n",
        "      moderate_storage[tag].append(newcolor)\n",
        "      hot_storage[tag].append(newcolor)\n",
        "\n",
        "\n",
        "  return (newcolor, labels[index[0]].split(\",\")[0].replace(\" \", \"\"), percentage[index[0]].item())\n",
        "  _, indices = torch.sort(out, descending=True)\n",
        "  [(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r1a1-7OAA5d"
      },
      "outputs": [],
      "source": [
        "'''imagenet 21 000'''\n",
        "@anvil.server.callable\n",
        "def imagenet21k():\n",
        "  # is more accurate but it's TOO detailed\n",
        "  import keras_efficientnet_v2\n",
        "  from keras_cv_attention_models import imagenet\n",
        "  import numpy\n",
        "  model = keras_efficientnet_v2.EfficientNetV2B3(pretrained='imagenet21k', num_classes=21843)\n",
        "  img_1 = Image.open(\"drive/My Drive/codejam/test1.png\").convert('RGB')\n",
        "\n",
        "  # there's gotta be a better way to do this, but converting PIL to numpy\n",
        "  na = numpy.array(img_1)\n",
        "  imm = tf.image.resize(na, model.input_shape[1:-1]) \n",
        "  imm2 = tf.keras.applications.imagenet_utils.preprocess_input(tf.expand_dims(imm, 0), mode='tf')\n",
        "  pred = model(imm2).numpy()\n",
        "  print(imagenet.decode_predictions_imagenet21k(pred))\n",
        "  return(imagenet.decode_predictions_imagenet21k(pred))\n",
        "  #print(keras.applications.imagenet_utils.decode_predictions(pred)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "VkghvsdaBjpt",
        "outputId": "cde13739-9b91-420d-cfd3-4f1bed3b0488"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-95cac3476493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/anvil/server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "anvil.server.wait_forever()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}